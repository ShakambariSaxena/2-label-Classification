{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMToypuYI1G9S9d5YWeRp31",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c9b42e7007442e2aa6047ffb769d1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b1d513cfb874fb6a32d9b48e4272b70",
              "IPY_MODEL_1a6403b8e36f4c7d9b3c3ea8a3cb9e2b",
              "IPY_MODEL_d84485ae988149cf8bc9ae3468dfe889"
            ],
            "layout": "IPY_MODEL_e616a18f6dab48f69f1220bca7a3134b"
          }
        },
        "7b1d513cfb874fb6a32d9b48e4272b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1e047090754152a5e9ea001082ead7",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff1176d30cd430f8ce6c76f4edae5fe",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "1a6403b8e36f4c7d9b3c3ea8a3cb9e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_591ca58ffaa74c5b8915ae73aeb198d3",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e992c4ae03984d0ea84e2dea9da4558a",
            "value": 714290682
          }
        },
        "d84485ae988149cf8bc9ae3468dfe889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6383b3102f44dbb8dbf9a769decebd9",
            "placeholder": "​",
            "style": "IPY_MODEL_cbc8343871cd4eddacf5fd4b10fe6803",
            "value": " 714M/714M [00:08&lt;00:00, 96.3MB/s]"
          }
        },
        "e616a18f6dab48f69f1220bca7a3134b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1e047090754152a5e9ea001082ead7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff1176d30cd430f8ce6c76f4edae5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "591ca58ffaa74c5b8915ae73aeb198d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e992c4ae03984d0ea84e2dea9da4558a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6383b3102f44dbb8dbf9a769decebd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc8343871cd4eddacf5fd4b10fe6803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShakambariSaxena/2-label-Classification/blob/main/2_label_classification_with_BERT_multilingual_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing libraires**"
      ],
      "metadata": {
        "id": "YBV8PKd63THN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVa1kAX8kQU3",
        "outputId": "13ed9167-d156-4e1c-fc4b-122060c68be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import nltk\n",
        "!python -m nltk.downloader popular\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gpIFOGJkXgs",
        "outputId": "13cea52c-be98-45fe-b44b-16434f5ad27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uploading Dataset**"
      ],
      "metadata": {
        "id": "DTeWdb6k3ZX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the zip file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "b67DBXwvkbN0",
        "outputId": "5c8b7557-30c2-409d-c68a-2dca0f7f0ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-74efde99-b022-4d0b-82e0-96d0ed462732\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-74efde99-b022-4d0b-82e0-96d0ed462732\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving transcripts.zip to transcripts.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = '/content/transcripts.zip'  # Replace with the actual path to your zip file\n",
        "folder_to_extract = 'transcript'  # Replace with the name of the folder you want to extract\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(folder_to_extract)\n",
        "\n",
        "print(\"Folder extraction complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9h5a0Cekdl_",
        "outputId": "066f5d14-3abf-4597-d2cd-b7bf1e1fca28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "corpus_dir = '/content/transcript/transcripts'\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "folder_names = [folder for folder in os.listdir(corpus_dir) if os.path.isdir(os.path.join(corpus_dir, folder))]\n",
        "folder_names.sort()\n",
        "\n",
        "for folder_name in folder_names:\n",
        "    folder_path = os.path.join(corpus_dir, folder_name)\n",
        "\n",
        "    # Get the list of text files in the folder\n",
        "    files = [file for file in os.listdir(folder_path) if file.endswith('.txt')]\n",
        "\n",
        "    if len(files) == 1:\n",
        "        # Process the single text file in the folder\n",
        "        file_path = os.path.join(folder_path, files[0])\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    match = re.search(r\"['\\\"](.*?)\\[([\\d]+)\\]\", line)\n",
        "                    if match:\n",
        "                        sentence = match.group(1)\n",
        "                        label = match.group(2)\n",
        "\n",
        "                        sentence = re.sub(r'^\\d+\\.\\s+', '', sentence)\n",
        "                        sentence = re.sub(r'[^\\w\\s]', '', sentence)  # Remove symbols\n",
        "                        sentence = sentence.lower()\n",
        "\n",
        "                        texts.append(sentence)\n",
        "                        labels.append(int(label))\n",
        "\n",
        "    elif len(files) == 2:\n",
        "        # Process Channel_1 text file\n",
        "        file_path = os.path.join(folder_path, 'Channel_1.txt')\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    match = re.search(r\"['\\\"](.*?)\\[([\\d]+)\\]\", line)\n",
        "                    if match:\n",
        "                        sentence = match.group(1)\n",
        "                        label = match.group(2)\n",
        "\n",
        "                        sentence = re.sub(r'^\\d+\\.\\s+', '', sentence)\n",
        "                        sentence = re.sub(r'[^\\w\\s]', '', sentence)  # Remove symbols\n",
        "                        sentence = sentence.lower()\n",
        "\n",
        "                        texts.append(sentence)\n",
        "                        labels.append(int(label))\n",
        "\n",
        "        # Process Channel_2 text file\n",
        "        file_path = os.path.join(folder_path, 'Channel_2.txt')\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    match = re.search(r\"['\\\"](.*?)\\[([\\d]+)\\]\", line)\n",
        "                    if match:\n",
        "                        sentence = match.group(1)\n",
        "                        label = match.group(2)\n",
        "\n",
        "                        sentence = re.sub(r'^\\d+\\.\\s+', '', sentence)\n",
        "                        sentence = re.sub(r'[^\\w\\s]', '', sentence)  # Remove symbols\n",
        "                        sentence = sentence.lower()\n",
        "\n",
        "                        texts.append(sentence)\n",
        "                        labels.append(int(label))\n",
        "\n",
        "# Write the text and label data to a new file in the current directory\n",
        "output_file = 'dataset.txt'\n",
        "with open(output_file, 'w') as f:\n",
        "    for text, label in zip(texts, labels):\n",
        "        line = f'{label}\\t{text}\\n'\n",
        "        f.write(line)\n"
      ],
      "metadata": {
        "id": "mFSAtwsB5cZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Dataset**"
      ],
      "metadata": {
        "id": "Ng_nFvJo3dcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "\n",
        "def process_text(input_file, output_file):\n",
        "    english_stopwords = set(stopwords.words('english'))\n",
        "    german_stopwords = set(stopwords.words('german'))\n",
        "    stemmer = SnowballStemmer(\"german\")\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    with open(input_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    processed_lines = []\n",
        "    for line in lines:\n",
        "        label, text = line.split('\\t')\n",
        "\n",
        "        # Skip the line if the label is 4 or 1\n",
        "        if label in ['4', '1']:\n",
        "            continue\n",
        "\n",
        "        blob = TextBlob(text)\n",
        "\n",
        "        # Remove stopwords and perform stemming and lemmatization\n",
        "        words = [lemmatizer.lemmatize(stemmer.stem(word.lower())) for word in blob.words\n",
        "                 if word.lower() not in english_stopwords and word.lower() not in german_stopwords]\n",
        "\n",
        "        processed_text = ' '.join(words)\n",
        "\n",
        "        # Skip processing if line becomes blank\n",
        "        if not processed_text.strip():\n",
        "            continue\n",
        "\n",
        "        processed_lines.append(f\"{label}\\t{processed_text}\\n\")\n",
        "\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.writelines(processed_lines)\n",
        "\n",
        "# Specify the paths to your input and output files\n",
        "input_file = '/content/dataset.txt'\n",
        "output_file = '/content/preprocessed_dataset.txt'\n",
        "\n",
        "# Call the function to process the text file\n",
        "process_text(input_file, output_file)\n"
      ],
      "metadata": {
        "id": "m4ECxmLhBteS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: Prepare the dataset\n",
        "sentences = []\n",
        "labels = []\n",
        "with open('/content/preprocessed_dataset.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            parts = line.split('\\t')\n",
        "            if len(parts) == 2:\n",
        "                label, sentence = parts\n",
        "                sentences.append(sentence)\n",
        "                labels.append(int(label))\n",
        "\n",
        "split_ratio = 0.8  # 80% for training, 20% for testing\n",
        "split_index = int(len(sentences) * split_ratio)\n",
        "train_sentences = sentences[:split_index]\n",
        "train_labels = labels[:split_index]\n",
        "test_sentences = sentences[split_index:]\n",
        "test_labels = labels[split_index:]\n",
        "\n",
        "# Step 3: Create train and test folders\n",
        "train_folder = '/content/train_dataset'\n",
        "test_folder = '/content/test_dataset'\n",
        "\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "# Save train dataset\n",
        "with open(os.path.join(train_folder, 'train_dataset.txt'), 'w') as file:\n",
        "    for sentence, label in zip(train_sentences, train_labels):\n",
        "        file.write(f'{label}\\t{sentence}\\n')\n",
        "\n",
        "# Save test dataset\n",
        "with open(os.path.join(test_folder, 'test_dataset.txt'), 'w') as file:\n",
        "    for sentence, label in zip(test_sentences, test_labels):\n",
        "        file.write(f'{label}\\t{sentence}\\n')\n",
        "\n",
        "# Step 4: Calculate label distributions\n",
        "train_label_counts = {label: train_labels.count(label) for label in set(train_labels)}\n",
        "test_label_counts = {label: test_labels.count(label) for label in set(test_labels)}\n",
        "\n",
        "# Step 5: Plot label distributions\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x=list(train_label_counts.keys()), y=list(train_label_counts.values()))\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Train Label Distribution')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.barplot(x=list(test_label_counts.keys()), y=list(test_label_counts.values()))\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Test Label Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(train_label_counts)\n",
        "print(test_label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HNzJDEF05lmN",
        "outputId": "9adf3af5-6ceb-452e-d7e9-c3552e05e1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2: 2133, 3: 4580}\n",
            "{2: 692, 3: 987}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Libraries for BERT model**"
      ],
      "metadata": {
        "id": "2yM5o0hQ3iiX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD65AA8WjuKu",
        "outputId": "a2eb4cab-147b-47e0-9ed4-e728aaaee689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing libraries**"
      ],
      "metadata": {
        "id": "4B3YkCq93qFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rQAmhuLUkEoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_file(file_path):\n",
        "    labels = []\n",
        "    sentences = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    for line in lines:\n",
        "        elements = line.strip().split('\\t')\n",
        "        label = int(elements[0])  # Assuming the label is the first element in each line\n",
        "        text = ' '.join(elements[1:])  # Combine the rest of the elements as the text\n",
        "        labels.append(label)\n",
        "        sentences.append(text)\n",
        "    return labels, sentences\n"
      ],
      "metadata": {
        "id": "A_oHSXRYkLFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "train_file = \"/content/train_dataset/train_dataset.txt\"\n",
        "labels_train,sentences_train = load_data_from_file(train_file)\n",
        "\n",
        "# Load testing data\n",
        "test_file = \"/content/test_dataset/test_dataset.txt\"\n",
        "labels_test,sentences_test = load_data_from_file(test_file)"
      ],
      "metadata": {
        "id": "lrnttbZ8kNp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Tokenize training data\n",
        "tokenized_train = tokenizer(sentences_train, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "input_ids_train = tokenized_train.input_ids\n",
        "attention_mask_train = tokenized_train.attention_mask\n",
        "labels_train = torch.tensor(labels_train)\n",
        "\n",
        "# Tokenize testing data\n",
        "tokenized_test = tokenizer(sentences_test, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "input_ids_test = tokenized_test.input_ids\n",
        "attention_mask_test = tokenized_test.attention_mask\n",
        "labels_test = torch.tensor(labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq6E2CZTk3y7",
        "outputId": "8b68fb27-6183-46f2-d7ca-1e3333cc0c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-c5f72fda673b>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels_train = torch.tensor(labels_train)\n",
            "<ipython-input-20-c5f72fda673b>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels_test = torch.tensor(labels_test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating train,test and validation dataset**"
      ],
      "metadata": {
        "id": "5nO24yw63xLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "# Split the training data into training set and validation set (80-20 split)\n",
        "train_val_dataset = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n",
        "train_size = int(0.8 * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
        "\n",
        "# Tokenize training data\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Tokenize validation data\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "dataset_test = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "-NR5pshRKuoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Dropout\n",
        "# Step 3: Load the pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=(len(labels_train)))\n",
        "\n",
        "# Add dropout layer after the BERT model\n",
        "dropout_prob = 0.1  # You can adjust the dropout rate as needed\n",
        "model.bert.config.hidden_dropout_prob = dropout_prob\n",
        "model.dropout = Dropout(dropout_prob)\n",
        "\n",
        "# Step 4: Fine-tuning\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Add weight decay (L2 regularization) to the optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "8c9b42e7007442e2aa6047ffb769d1f2",
            "7b1d513cfb874fb6a32d9b48e4272b70",
            "1a6403b8e36f4c7d9b3c3ea8a3cb9e2b",
            "d84485ae988149cf8bc9ae3468dfe889",
            "e616a18f6dab48f69f1220bca7a3134b",
            "6c1e047090754152a5e9ea001082ead7",
            "9ff1176d30cd430f8ce6c76f4edae5fe",
            "591ca58ffaa74c5b8915ae73aeb198d3",
            "e992c4ae03984d0ea84e2dea9da4558a",
            "d6383b3102f44dbb8dbf9a769decebd9",
            "cbc8343871cd4eddacf5fd4b10fe6803"
          ]
        },
        "outputId": "f4ab5568-a09c-4b82-a09b-cc00ae29e7db",
        "id": "NUU0isQqM3nf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c9b42e7007442e2aa6047ffb769d1f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intializing BERT multlingual model with Cross entroply loss function**"
      ],
      "metadata": {
        "id": "xIrmS4Qo4H9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Load the pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=(len(labels_train)))\n",
        "\n",
        "# Step 4: Fine-tuning\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "gradient_accumulation_steps = 2\n",
        "num_train_steps = len(train_dataloader) // gradient_accumulation_steps\n",
        "num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * num_train_steps)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "patience = 2\n",
        "no_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_mask, labels = batch\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Optional gradient clipping\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "        correct_predictions += (predicted_labels == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader) * gradient_accumulation_steps\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            logits = outputs.logits\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "            val_correct_predictions += (predicted_labels == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    val_losses.append(average_val_loss)\n",
        "    val_accuracy = val_correct_predictions / val_total_predictions\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {average_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if average_val_loss < best_val_loss:\n",
        "        best_val_loss = average_val_loss\n",
        "        no_improvement = 0\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "\n",
        "    if no_improvement >= patience:\n",
        "        print(\"No improvement on validation set. Finish training.\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3331f7a-7ee6-4103-ada5-6414170c58fd",
        "id": "UjRiVUStqFms"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 8.5782, Train Accuracy: 0.6588, Validation Loss: 1.6089, Validation Accuracy: 0.6701\n",
            "Epoch 2/10, Train Loss: 1.8724, Train Accuracy: 0.6877, Validation Loss: 0.6247, Validation Accuracy: 0.6940\n",
            "Epoch 3/10, Train Loss: 1.1150, Train Accuracy: 0.7395, Validation Loss: 0.5777, Validation Accuracy: 0.7349\n",
            "Epoch 4/10, Train Loss: 0.9013, Train Accuracy: 0.8009, Validation Loss: 0.6014, Validation Accuracy: 0.7334\n",
            "Epoch 5/10, Train Loss: 0.7625, Train Accuracy: 0.8345, Validation Loss: 0.5771, Validation Accuracy: 0.7431\n",
            "Epoch 6/10, Train Loss: 0.6659, Train Accuracy: 0.8574, Validation Loss: 0.6099, Validation Accuracy: 0.7394\n",
            "Epoch 7/10, Train Loss: 0.5848, Train Accuracy: 0.8754, Validation Loss: 0.6805, Validation Accuracy: 0.7386\n",
            "No improvement on validation set. Finish training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Initialize evaluation metrics\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Evaluate on the test data\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "\n",
        "        predictions.extend(predicted_labels.cpu().numpy())\n",
        "        true_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average=\"macro\")\n",
        "recall = recall_score(true_labels, predictions, average=\"macro\")\n",
        "f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Print the classification report\n",
        "target_names = [\"2\", \"3\"]  # Replace with your actual class names\n",
        "print(classification_report(true_labels, predictions, target_names=target_names))\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbf2718-86f9-440c-b647-1537d41e0307",
        "id": "jbPQXAL4ufXG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6504\n",
            "Precision: 0.6486\n",
            "Recall: 0.6035\n",
            "F1-score: 0.5939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.65      0.34      0.44       692\n",
            "           3       0.65      0.87      0.75       987\n",
            "\n",
            "    accuracy                           0.65      1679\n",
            "   macro avg       0.65      0.60      0.59      1679\n",
            "weighted avg       0.65      0.65      0.62      1679\n",
            "\n",
            "Confusion Matrix:\n",
            "[[233 459]\n",
            " [128 859]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "Ayg2KfEZ4T2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "d29fd0d9-49ff-445d-b501-f184fb071d41",
        "id": "HaC7Sn0WulK0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[233 459]\n",
            " [128 859]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMZ0lEQVR4nO3de5hNdf//8dcezDbmaJhjMoSYccgxJiGFiVFEt5QYItEQJtJ0I3SYUjkWyi3cooMOulEOEZJxLJJTCFMxRjQzDnMys35/+NnftjVqtmbbw34+vte6rmatz17rvfZ19e19vz5rfbbFMAxDAAAAwJ94uLoAAAAAlDw0iQAAADChSQQAAIAJTSIAAABMaBIBAABgQpMIAAAAE5pEAAAAmNAkAgAAwIQmEQAAACY0iQD+0oEDB9SuXTv5+/vLYrFo8eLFxXr+I0eOyGKxaO7cucV63uvZXXfdpbvuusvVZQBwczSJwHXg0KFDeuKJJ3TLLbeobNmy8vPzU/PmzTVlyhRlZWU59dpxcXHatWuXXnrpJc2fP1+NGzd26vWupd69e8tiscjPz6/Q7/HAgQOyWCyyWCx6/fXXHT7/sWPHNHbsWO3YsaMYqgWAa6u0qwsA8NeWLVumf/3rX7JarerVq5fq1Kmj3NxcbdiwQSNGjNDu3bv1zjvvOOXaWVlZSk5O1r///W8NGjTIKdeIiIhQVlaWypQp45Tz/53SpUvr/PnzWrJkibp162Z3bMGCBSpbtqyys7Ov6tzHjh3TuHHjVKVKFdWvX7/In1u5cuVVXQ8AihNNIlCCHT58WN27d1dERITWrFmjsLAw27H4+HgdPHhQy5Ytc9r1T548KUkKCAhw2jUsFovKli3rtPP/HavVqubNm+v99983NYkLFy5UbGysPvnkk2tSy/nz51WuXDl5enpek+sBwF9huhkowSZMmKCzZ89q9uzZdg3iJdWrV9eQIUNsf1+4cEEvvPCCqlWrJqvVqipVqui5555TTk6O3eeqVKmijh07asOGDbr99ttVtmxZ3XLLLfrvf/9rGzN27FhFRERIkkaMGCGLxaIqVapIujhNe+mf/2zs2LGyWCx2+1atWqU777xTAQEB8vHxUc2aNfXcc8/Zjl/pmcQ1a9aoRYsW8vb2VkBAgDp16qS9e/cWer2DBw+qd+/eCggIkL+/v/r06aPz589f+Yu9zCOPPKIvv/xS6enptn1bt27VgQMH9Mgjj5jGnz59WsOHD1fdunXl4+MjPz8/tW/fXjt37rSNWbt2rZo0aSJJ6tOnj23a+tJ93nXXXapTp462b9+uli1bqly5crbv5fJnEuPi4lS2bFnT/cfExKh8+fI6duxYke8VAIqKJhEowZYsWaJbbrlFd9xxR5HG9+vXT2PGjFHDhg01adIktWrVSklJSerevbtp7MGDB/Xggw+qbdu2euONN1S+fHn17t1bu3fvliR16dJFkyZNkiQ9/PDDmj9/viZPnuxQ/bt371bHjh2Vk5Oj8ePH64033tD999+vb7/99i8/99VXXykmJkZpaWkaO3asEhIStHHjRjVv3lxHjhwxje/WrZvOnDmjpKQkdevWTXPnztW4ceOKXGeXLl1ksVj06aef2vYtXLhQtWrVUsOGDU3jf/75Zy1evFgdO3bUxIkTNWLECO3atUutWrWyNWyRkZEaP368JKl///6aP3++5s+fr5YtW9rOc+rUKbVv317169fX5MmT1bp160LrmzJlioKCghQXF6f8/HxJ0ttvv62VK1dq2rRpCg8PL/K9AkCRGQBKpIyMDEOS0alTpyKN37FjhyHJ6Nevn93+4cOHG5KMNWvW2PZFREQYkoz169fb9qWlpRlWq9V4+umnbfsOHz5sSDJee+01u3PGxcUZERERphqef/5548//b2XSpEmGJOPkyZNXrPvSNebMmWPbV79+fSM4ONg4deqUbd/OnTsNDw8Po1evXqbrPfbYY3bnfOCBB4wKFSpc8Zp/vg9vb2/DMAzjwQcfNO655x7DMAwjPz/fCA0NNcaNG1fod5CdnW3k5+eb7sNqtRrjx4+37du6davp3i5p1aqVIcmYOXNmocdatWplt2/FihWGJOPFF180fv75Z8PHx8fo3Lnz394jAFwtkkSghMrMzJQk+fr6Fmn8F198IUlKSEiw2//0009LkunZxaioKLVo0cL2d1BQkGrWrKmff/75qmu+3KVnGT///HMVFBQU6TPHjx/Xjh071Lt3bwUGBtr216tXT23btrXd558NGDDA7u8WLVro1KlTtu+wKB555BGtXbtWqampWrNmjVJTUwudapYuPsfo4XHx/33m5+fr1KlTtqn07777rsjXtFqt6tOnT5HGtmvXTk888YTGjx+vLl26qGzZsnr77beLfC0AcBRNIlBC+fn5SZLOnDlTpPFHjx6Vh4eHqlevbrc/NDRUAQEBOnr0qN3+ypUrm85Rvnx5/fHHH1dZsdlDDz2k5s2bq1+/fgoJCVH37t310Ucf/WXDeKnOmjVrmo5FRkbq999/17lz5+z2X34v5cuXlySH7qVDhw7y9fXVhx9+qAULFqhJkyam7/KSgoICTZo0STVq1JDValXFihUVFBSkH374QRkZGUW+5k033eTQSyqvv/66AgMDtWPHDk2dOlXBwcFF/iwAOIomESih/Pz8FB4erh9//NGhz13+4siVlCpVqtD9hmFc9TUuPS93iZeXl9avX6+vvvpKPXv21A8//KCHHnpIbdu2NY39J/7JvVxitVrVpUsXzZs3T5999tkVU0RJevnll5WQkKCWLVvqvffe04oVK7Rq1SrVrl27yImpdPH7ccT333+vtLQ0SdKuXbsc+iwAOIomESjBOnbsqEOHDik5Oflvx0ZERKigoEAHDhyw23/ixAmlp6fb3lQuDuXLl7d7E/iSy9NKSfLw8NA999yjiRMnas+ePXrppZe0Zs0aff3114We+1Kd+/fvNx3bt2+fKlasKG9v7392A1fwyCOP6Pvvv9eZM2cKfdnnko8//litW7fW7Nmz1b17d7Vr105t2rQxfSdFbdiL4ty5c+rTp4+ioqLUv39/TZgwQVu3bi228wPA5WgSgRLsmWeekbe3t/r166cTJ06Yjh86dEhTpkyRdHG6VJLpDeSJEydKkmJjY4utrmrVqikjI0M//PCDbd/x48f12Wef2Y07ffq06bOXFpW+fFmeS8LCwlS/fn3NmzfPrun68ccftXLlStt9OkPr1q31wgsv6M0331RoaOgVx5UqVcqUUi5atEi//fab3b5LzWxhDbWjRo4cqZSUFM2bN08TJ05UlSpVFBcXd8XvEQD+KRbTBkqwatWqaeHChXrooYcUGRlp94srGzdu1KJFi9S7d29J0m233aa4uDi98847Sk9PV6tWrbRlyxbNmzdPnTt3vuLyKleje/fuGjlypB544AE99dRTOn/+vGbMmKFbb73V7sWN8ePHa/369YqNjVVERITS0tI0ffp0VapUSXfeeecVz//aa6+pffv2io6OVt++fZWVlaVp06bJ399fY8eOLbb7uJyHh4dGjRr1t+M6duyo8ePHq0+fPrrjjju0a9cuLViwQLfccovduGrVqikgIEAzZ86Ur6+vvL291bRpU1WtWtWhutasWaPp06fr+eefty3JM2fOHN11110aPXq0JkyY4ND5AKBIXPx2NYAi+Omnn4zHH3/cqFKliuHp6Wn4+voazZs3N6ZNm2ZkZ2fbxuXl5Rnjxo0zqlatapQpU8a4+eabjcTERLsxhnFxCZzY2FjTdS5feuVKS+AYhmGsXLnSqFOnjuHp6WnUrFnTeO+990xL4Kxevdro1KmTER4ebnh6ehrh4eHGww8/bPz000+ma1y+TMxXX31lNG/e3PDy8jL8/PyM++67z9izZ4/dmEvXu3yJnTlz5hiSjMOHD1/xOzUM+yVwruRKS+A8/fTTRlhYmOHl5WU0b97cSE5OLnTpms8//9yIiooySpcubXefrVq1MmrXrl3oNf98nszMTCMiIsJo2LChkZeXZzdu2LBhhoeHh5GcnPyX9wAAV8NiGA482Q0AAAC3wDOJAAAAMKFJBAAAgAlNIgAAAExoEgEAAGBCkwgAAAATmkQAAACY0CQCAADA5Ib8xZWDaVmuLgGAk7y341dXlwDASca2q+Gya3s1GOS0c2d9/6bTzu1MJIkAAAAwuSGTRAAAAIdYyM0uR5MIAABgsbi6ghKHthkAAAAmJIkAAABMN5vwjQAAAMCEJBEAAIBnEk1IEgEAAGBCkggAAMAziSZ8IwAAADAhSQQAAOCZRBOaRAAAAKabTfhGAAAAYEKSCAAAwHSzCUkiAAAATEgSAQAAeCbRhG8EAAAAJiSJAAAAPJNoQpIIAAAAE5JEAAAAnkk0oUkEAABgutmEthkAAAAmJIkAAABMN5vwjQAAAMCEJBEAAIAk0YRvBAAAACYkiQAAAB683Xw5kkQAAACYkCQCAADwTKIJTSIAAACLaZvQNgMAAMCEJBEAAIDpZhO+EQAAgBIiPz9fo0ePVtWqVeXl5aVq1arphRdekGEYtjGGYWjMmDEKCwuTl5eX2rRpowMHDtid5/Tp0+rRo4f8/PwUEBCgvn376uzZsw7VQpMIAABgsThvc8Crr76qGTNm6M0339TevXv16quvasKECZo2bZptzIQJEzR16lTNnDlTmzdvlre3t2JiYpSdnW0b06NHD+3evVurVq3S0qVLtX79evXv39+hWphuBgAAKCE2btyoTp06KTY2VpJUpUoVvf/++9qyZYukiyni5MmTNWrUKHXq1EmS9N///lchISFavHixunfvrr1792r58uXaunWrGjduLEmaNm2aOnTooNdff13h4eFFqoUkEQAAwOLhtC0nJ0eZmZl2W05OTqFl3HHHHVq9erV++uknSdLOnTu1YcMGtW/fXpJ0+PBhpaamqk2bNrbP+Pv7q2nTpkpOTpYkJScnKyAgwNYgSlKbNm3k4eGhzZs3F/kroUkEAABwoqSkJPn7+9ttSUlJhY599tln1b17d9WqVUtlypRRgwYNNHToUPXo0UOSlJqaKkkKCQmx+1xISIjtWGpqqoKDg+2Oly5dWoGBgbYxRcF0MwAAgBPXSUxMTFRCQoLdPqvVWujYjz76SAsWLNDChQtVu3Zt7dixQ0OHDlV4eLji4uKcVmNhaBIBAACcuASO1Wq9YlN4uREjRtjSREmqW7eujh49qqSkJMXFxSk0NFSSdOLECYWFhdk+d+LECdWvX1+SFBoaqrS0NLvzXrhwQadPn7Z9viiYbgYAACghzp8/Lw8P+/asVKlSKigokCRVrVpVoaGhWr16te14ZmamNm/erOjoaElSdHS00tPTtX37dtuYNWvWqKCgQE2bNi1yLSSJAAAAJeRn+e677z699NJLqly5smrXrq3vv/9eEydO1GOPPSZJslgsGjp0qF588UXVqFFDVatW1ejRoxUeHq7OnTtLkiIjI3Xvvffq8ccf18yZM5WXl6dBgwape/fuRX6zWaJJBAAAKDGmTZum0aNH68knn1RaWprCw8P1xBNPaMyYMbYxzzzzjM6dO6f+/fsrPT1dd955p5YvX66yZcvaxixYsECDBg3SPffcIw8PD3Xt2lVTp051qBaL8eclvG8QB9OyXF0CACd5b8evri4BgJOMbVfDZdf26jDFaefO+mKI087tTDyTCAAAABOmmwEAAErIM4klCUkiAAAATEgSAQAAnLhO4vWKJhEAAIAm0YRvBAAAACYkiQAAALy4YkKSCAAAABOSRAAAAJ5JNOEbAQAAgAlJIgAAAM8kmpAkAgAAwIQkEQAAgGcSTWgSAQAAmG42oW0GAACACUkiAABwexaSRBOSRAAAAJiQJAIAALdHkmhGkggAAAATkkQAAACCRBOSRAAAAJiQJAIAALfHM4lmNIkAAMDt0SSaMd0MAAAAE5JEAADg9kgSzUgSAQAAYEKSCAAA3B5JohlJIgAAAExIEgEAAAgSTUgSAQAAYEKSCAAA3B7PJJqRJAIAAMCEJBEAALg9kkQzmkQAAOD2aBLNmG4GAACACUkiAABweySJZiSJAAAAMCFJBAAAIEg0IUkEAACACUkiAABwezyTaEaSCAAAABOSRAAA4PZIEs1oEgEAgNujSTRjuhkAAAAmJIkAAAAEiSYkiQAAADAhSQQAAG6PZxLNSBIBAABgQpIIAADcHkmiGUkiAAAATEgSAQCA2yNJNKNJBAAAbo8m0YzpZgAAgBKiSpUqslgspi0+Pl6SlJ2drfj4eFWoUEE+Pj7q2rWrTpw4YXeOlJQUxcbGqly5cgoODtaIESN04cIFh2uhSQQAALA4cXPA1q1bdfz4cdu2atUqSdK//vUvSdKwYcO0ZMkSLVq0SOvWrdOxY8fUpUsX2+fz8/MVGxur3Nxcbdy4UfPmzdPcuXM1ZswYx78SwzAMhz9Vwh1My3J1CQCc5L0dv7q6BABOMrZdDZddO3zAp04797GZXf5+0BUMHTpUS5cu1YEDB5SZmamgoCAtXLhQDz74oCRp3759ioyMVHJyspo1a6Yvv/xSHTt21LFjxxQSEiJJmjlzpkaOHKmTJ0/K09OzyNcmSQQAAG6vsCne4tpycnKUmZlpt+Xk5PxtTbm5uXrvvff02GOPyWKxaPv27crLy1ObNm1sY2rVqqXKlSsrOTlZkpScnKy6devaGkRJiomJUWZmpnbv3u3Qd0KTCAAA4ERJSUny9/e325KSkv72c4sXL1Z6erp69+4tSUpNTZWnp6cCAgLsxoWEhCg1NdU25s8N4qXjl445grebAQCA23Pm282JiYlKSEiw22e1Wv/2c7Nnz1b79u0VHh7urNL+Ek0iAACAE1mt1iI1hX929OhRffXVV/r00/97VjI0NFS5ublKT0+3SxNPnDih0NBQ25gtW7bYnevS28+XxhQV080AAMDtOfOZxKsxZ84cBQcHKzY21ravUaNGKlOmjFavXm3bt3//fqWkpCg6OlqSFB0drV27diktLc02ZtWqVfLz81NUVJRDNZAkAgAAlKC1tAsKCjRnzhzFxcWpdOn/a9X8/f3Vt29fJSQkKDAwUH5+fho8eLCio6PVrFkzSVK7du0UFRWlnj17asKECUpNTdWoUaMUHx/vcJpJkwgAAFCCfPXVV0pJSdFjjz1mOjZp0iR5eHioa9euysnJUUxMjKZPn247XqpUKS1dulQDBw5UdHS0vL29FRcXp/HjxztcB+skAriusE4icONy5TqJlQf/z2nnTpl2v9PO7Uw8kwgAAAATppsBAIDbc+YSONcrkkQAAACYkCSixPlo/mxtXL9avx49Ik+rVZF1blOfgUNVqXIV25hpr72gHds26/TvJ1XWq5wi696mPgOG6OaIqpKkzIx0vTb+OR05dECZmekKKB+oZnfepbj+g1XO28dFdwbgcntWLtLOJfN06133q1HX/pKk1VOeVdrBH+3GVW9+r5p0H2T7O3X/Du1a9p7Sjx1VaU+rqja9R/U69pJHqVLXtH7cOEgSzWgSUeLs2rFdsQ88pFsjays/P1/z3p6mUQkDNXP+pyrr5SVJql4zUq3bdlBQSKjOZGZqwZyZGp0wULM/WqZSpUrJ4uGhZnfepV6Px8s/oLyO/fqLZkxK0pnMDD3z/CsuvkMAknTq6E86+O1yBYRXMR2rdkeM6sY+avu7dJn/W7rjj19/1rqZY1W73UNq1jNBWemntPXDt2QUFKjBA32vRemAW6BJRInzwhvT7f5OeG68Hrn/bh3cv0d16jeSJLW//0Hb8ZCwm9SrX7wG9emmtNRjCrvpZvn6+in2gW62McGh4Yp9oJs+eX/etbkJAH8pLydLyfNe1+0PD9buFR+YjpfytMrLr3yhn0357hsFhFdVnfYPS5J8g8JVv1MffTvnVdVp/7DKlC3n1NpxYyJJNKNJRIl37txZSZKPn3+hx7OzsrTqi88VEnaTKgYX/pNDp35P08Z1q1XntkZOqxNA0W37aIbCazdRaK36hTaJR7et1ZGta+XlF6DwOrerzr3dVdqzrCQp/0KeSpUuYze+VBmr8vNydfqXgwqpUe+a3ANuMPSIJi5vErOysrR9+3YFBgaafi4mOztbH330kXr16nXFz+fk5CgnJ+eyfQUOryqOkqmgoEDvTH1NUXXrq8ot1e2OLf3sQ82ZMVnZWVmqVLmKXpo0U2XK2P+H49Wxz2rzhrXKycnW7c1bacjI569l+QAKcXT7Ov3xyyHFjJhU6PGIxnfJOzBIXv4VlP7bYe3431ydOfGbWjz+b0lSWGRD/bT2fzqybZ0qN7xT2Zl/6Mfl70uSsjL+uGb3AdzoXPp2808//aTIyEi1bNlSdevWVatWrXT8+HHb8YyMDPXp0+cvz5GUlCR/f3+77e2przm7dFwjMyYm6ejhgxo59lXTsdZtO2jq7A/06rTZCr85QkljnlHuZf+D4fHBwzVl9vsanTRZqb/9ollvvn6tSgdQiHN/nNT2T2YpOm64SpXxLHRM9eb3KiyykQLCq6hKk9Zq9miCfv0hWWdOXvzvQ1hkQ9Xv3EfbPnxLHw17QEtfeELhUY0lMWWIq1fSfru5JHBpkjhy5EjVqVNH27ZtU3p6uoYOHarmzZtr7dq1qly5cpHOkZiYqISEBLt9v2QUOKNcXGMzJiVpS/J6vTrtXVUMDjEd9/bxlbePr266OUI1a9fTQx1aaOM3a3RXm/a2MYEVKiqwQkXdHFFVvn7+eia+jx6O66/AikHX8lYA/H9/pBxUzpl0rZgwxLbPKChQ2qHdOrB+qbpN+kweHvZvKFesUlOSdPb3Y/INCpMk1br7AdVs3VlZmafl6eWjc6fTtHPJPPlULPyREwCOc2mTuHHjRn311VeqWLGiKlasqCVLlujJJ59UixYt9PXXX8vb2/tvz2G1Wk1Ty9ZsfpbvemYYhmZOfkXJ69coaep/FBp+U1E+JBlSXm7ulYcUXPwfD3l5Vx4DwLlCat6m9olv2u3bvGCK/EIqKbJNV1ODKEl//PazJKmsX6DdfovFonL+FSRdnMIuVz5I5W+u5qTKcaO7nhM/Z3Fpk5iVlaXSpf+vBIvFohkzZmjQoEFq1aqVFi5c6MLq4CrTJ76sdV99qdEvT5ZXOW+dPvW7JMnbx0dWa1kdP/arvlm9Qg1uj5Z/QHn9nnZCixbMkafVqibRLSRJW5O/UfrpU6oRWUdeXl46eviQ3p0+WVF16yskrAhNJwCnKFO2nGnJm9KeVnl6+yogvIrOnDyuo9vXKjyqiTy9fZV+7Ii+/3SWgqrXUfmbqto+s/erTxQW1UgWi0W/7Nyovas+VvM+IwttMgFcHZc2ibVq1dK2bdsUGRlpt//NNy/+r8z7778+fxAb/8wXixdJkp59qp/d/qGJ49S2Qyd5enpq9w/f6fNFC3T2TKYCAiuozm0N9fqMeQoofzFp8LSW1fKln2rWm68rLzdPFYNDdEere/SvHn/9jCsA1/IoXVqp+3dq/9f/04XcbJUrX1GVbrtDdWK62407tme7dq/8SAUX8hRwU1W1eHyUwms3dlHVuBEQJJpZDMMwXHXxpKQkffPNN/riiy8KPf7kk09q5syZKihw7BnDg2lMNwM3qvd2/OrqEgA4ydh2NVx27erDv3TauQ++3v7vB5VALm0SnYUmEbhx0SQCNy5XNok1Rix32rkPvHav087tTC5fJxEAAMDVmG42c+k6iQAAACiZSBIBAIDbYwkcM5JEAAAAmJAkAgAAt0eQaEaSCAAAABOSRAAA4PY8PIgSL0eSCAAAABOSRAAA4PZ4JtGMJhEAALg9lsAxY7oZAAAAJiSJAADA7REkmpEkAgAAwIQkEQAAuD2eSTQjSQQAAIAJSSIAAHB7JIlmJIkAAAAwIUkEAABujyDRjCYRAAC4PaabzZhuBgAAgAlJIgAAcHsEiWYkiQAAADAhSQQAAG6PZxLNSBIBAABgQpIIAADcHkGiGUkiAAAATEgSAQCA2+OZRDOSRAAAAJiQJAIAALdHkGhGkwgAANwe081mTDcDAADAhCQRAAC4PYJEM5JEAAAAmJAkAgAAt8cziWYkiQAAADAhSQQAAG6PINGMJBEAAAAmJIkAAMDt8UyiGUkiAABwexaL8zZH/fbbb3r00UdVoUIFeXl5qW7dutq2bZvtuGEYGjNmjMLCwuTl5aU2bdrowIEDduc4ffq0evToIT8/PwUEBKhv3746e/asQ3XQJAIAAJQQf/zxh5o3b64yZcroyy+/1J49e/TGG2+ofPnytjETJkzQ1KlTNXPmTG3evFne3t6KiYlRdna2bUyPHj20e/durVq1SkuXLtX69evVv39/h2qxGIZhFNudlRAH07JcXQIAJ3lvx6+uLgGAk4xtV8Nl127xxgannfurQU2Uk5Njt89qtcpqtZrGPvvss/r222/1zTffFHouwzAUHh6up59+WsOHD5ckZWRkKCQkRHPnzlX37t21d+9eRUVFaevWrWrcuLEkafny5erQoYN+/fVXhYeHF6lukkQAAAAnSkpKkr+/v92WlJRU6Nj//e9/aty4sf71r38pODhYDRo00KxZs2zHDx8+rNTUVLVp08a2z9/fX02bNlVycrIkKTk5WQEBAbYGUZLatGkjDw8Pbd68uch10yQCAAC3Z7FYnLYlJiYqIyPDbktMTCy0jp9//lkzZsxQjRo1tGLFCg0cOFBPPfWU5s2bJ0lKTU2VJIWEhNh9LiQkxHYsNTVVwcHBdsdLly6twMBA25ii4O1mAAAAJ7rS1HJhCgoK1LhxY7388suSpAYNGujHH3/UzJkzFRcX58wyTUgSAQCA2yspbzeHhYUpKirKbl9kZKRSUlIkSaGhoZKkEydO2I05ceKE7VhoaKjS0tLsjl+4cEGnT5+2jSkKmkQAAIASonnz5tq/f7/dvp9++kkRERGSpKpVqyo0NFSrV6+2Hc/MzNTmzZsVHR0tSYqOjlZ6erq2b99uG7NmzRoVFBSoadOmRa6F6WYAAOD2Sspi2sOGDdMdd9yhl19+Wd26ddOWLVv0zjvv6J133pF0sc6hQ4fqxRdfVI0aNVS1alWNHj1a4eHh6ty5s6SLyeO9996rxx9/XDNnzlReXp4GDRqk7t27F/nNZokmEQAAoMT8dnOTJk302WefKTExUePHj1fVqlU1efJk9ejRwzbmmWee0blz59S/f3+lp6frzjvv1PLly1W2bFnbmAULFmjQoEG655575OHhoa5du2rq1KkO1cI6iQCuK6yTCNy4XLlOYuspG5127q+H3OG0czsTSSIAAHB7JWW6uSThxRUAAACYkCQCAAC3R5BoRpIIAAAAE5JEAADg9jyIEk1IEgEAAGBCkggAANweQaIZTSIAAHB7LIFjxnQzAAAATEgSAQCA2/MgSDQhSQQAAIAJSSIAAHB7PJNoRpIIAAAAE5JEAADg9ggSzUgSAQAAYEKSCAAA3J5FRImXo0kEAABujyVwzJhuBgAAgAlJIgAAcHssgWNGkggAAAATkkQAAOD2CBLNSBIBAABgQpIIAADcngdRoonDSeK8efO0bNky29/PPPOMAgICdMcdd+jo0aPFWhwAAABcw+Em8eWXX5aXl5ckKTk5WW+99ZYmTJigihUratiwYcVeIAAAgLNZLM7brlcOTzf/8ssvql69uiRp8eLF6tq1q/r376/mzZvrrrvuKu76AAAAnI4lcMwcThJ9fHx06tQpSdLKlSvVtm1bSVLZsmWVlZVVvNUBAADAJRxOEtu2bat+/fqpQYMG+umnn9ShQwdJ0u7du1WlSpXirg8AAMDpCBLNHE4S33rrLUVHR+vkyZP65JNPVKFCBUnS9u3b9fDDDxd7gQAAALj2HE4SAwIC9Oabb5r2jxs3rlgKAgAAuNZYAsesSE3iDz/8UOQT1qtX76qLAQAAQMlQpCaxfv36slgsMgyj0OOXjlksFuXn5xdrgQAAAM5GjmhWpCbx8OHDzq4DAAAAJUiRmsSIiAhn1wEAAOAyrJNo5vDbzZI0f/58NW/eXOHh4baf4ps8ebI+//zzYi0OAADgWvCwOG+7XjncJM6YMUMJCQnq0KGD0tPTbc8gBgQEaPLkycVdHwAAAFzA4SZx2rRpmjVrlv7973+rVKlStv2NGzfWrl27irU4AACAa8FisThtu1453CQePnxYDRo0MO23Wq06d+5csRQFAAAA13K4Saxatap27Nhh2r98+XJFRkYWR00AAADXlMXivO165fAvriQkJCg+Pl7Z2dkyDENbtmzR+++/r6SkJP3nP/9xRo0AAAC4xhxuEvv16ycvLy+NGjVK58+f1yOPPKLw8HBNmTJF3bt3d0aNAAAATnU9PzvoLA43iZLUo0cP9ejRQ+fPn9fZs2cVHBxc3HUBAADAha6qSZSktLQ07d+/X9LF7jsoKKjYigIAALiWruf1DJ3F4RdXzpw5o549eyo8PFytWrVSq1atFB4erkcffVQZGRnOqBEAAMCpWALHzOEmsV+/ftq8ebOWLVum9PR0paena+nSpdq2bZueeOIJZ9QIAACAa8zh6ealS5dqxYoVuvPOO237YmJiNGvWLN17773FWhwAAMC1cP3mfc7jcJJYoUIF+fv7m/b7+/urfPnyxVIUAAAAXMvhJnHUqFFKSEhQamqqbV9qaqpGjBih0aNHF2txAAAA14KHxeK07XpVpOnmBg0a2D14eeDAAVWuXFmVK1eWJKWkpMhqterkyZM8lwgAAHADKFKT2LlzZyeXAQAA4DrXceDnNEVqEp9//nln1wEAAIAS5KoX0wYAALhRXM/rGTqLwy+u5Ofn6/XXX9ftt9+u0NBQBQYG2m0AAAC4OmPHjjUtxl2rVi3b8ezsbMXHx6tChQry8fFR165ddeLECbtzpKSkKDY2VuXKlVNwcLBGjBihCxcuOFyLw03iuHHjNHHiRD300EPKyMhQQkKCunTpIg8PD40dO9bhAgAAAFzNYnHe5qjatWvr+PHjtm3Dhg22Y8OGDdOSJUu0aNEirVu3TseOHVOXLl1sx/Pz8xUbG6vc3Fxt3LhR8+bN09y5czVmzBiH63B4unnBggWaNWuWYmNjNXbsWD388MOqVq2a6tWrp02bNumpp55yuAgAAABXKklL1ZQuXVqhoaGm/RkZGZo9e7YWLlyou+++W5I0Z84cRUZGatOmTWrWrJlWrlypPXv26KuvvlJISIjq16+vF154QSNHjtTYsWPl6elZ5DocThJTU1NVt25dSZKPj4/t95o7duyoZcuWOXo6AACAG1pOTo4yMzPttpycnCuOP3DggMLDw3XLLbeoR48eSklJkSRt375deXl5atOmjW1srVq1VLlyZSUnJ0uSkpOTVbduXYWEhNjGxMTEKDMzU7t373aoboebxEqVKun48eOSpGrVqmnlypWSpK1bt8pqtTp6OgAAAJdz5nRzUlKS/P397bakpKRC62jatKnmzp2r5cuXa8aMGTp8+LBatGihM2fOKDU1VZ6engoICLD7TEhIiO1HTlJTU+0axEvHLx1zhMPTzQ888IBWr16tpk2bavDgwXr00Uc1e/ZspaSkaNiwYY6eDgAA4IaWmJiohIQEu31XCtbat29v++d69eqpadOmioiI0EcffSQvLy+n1nk5h5vEV155xfbPDz30kCIiIrRx40bVqFFD9913X7EWBwAAcC04cwkcq9V61bOtAQEBuvXWW3Xw4EG1bdtWubm5Sk9Pt0sTT5w4YXuGMTQ0VFu2bLE7x6W3nwt7zvGvODzdfLlmzZopISFBTZs21csvv/xPTwcAAID/7+zZszp06JDCwsLUqFEjlSlTRqtXr7Yd379/v1JSUhQdHS1Jio6O1q5du5SWlmYbs2rVKvn5+SkqKsqha1sMwzCK4yZ27typhg0bKj8/vzhO949kO74UEIDrRPkmg1xdAgAnyfr+TZdde/Bne5127mkPRBZ57PDhw3XfffcpIiJCx44d0/PPP68dO3Zoz549CgoK0sCBA/XFF19o7ty58vPz0+DBgyVJGzdulHRxCZz69esrPDxcEyZMUGpqqnr27Kl+/fo5HObxiysAAAAlxK+//qqHH35Yp06dUlBQkO68805t2rRJQUFBkqRJkybJw8NDXbt2VU5OjmJiYjR9+nTb50uVKqWlS5dq4MCBio6Olre3t+Li4jR+/HiHayFJBHBdIUkEblyuTBKfWrzPaeee2rnW3w8qgUgSAQCA2/MoOWtplxhFbhIvf3X7cidPnvzHxQAAAKBkKHKT+P333//tmJYtW/6jYgAAAFyBJNGsyE3i119/7cw6AAAAUILwTCIAAHB7zlxM+3r1jxfTBgAAwI2HJBEAALg9nkk0I0kEAACACUkiAABwezySaHZVSeI333yjRx99VNHR0frtt98kSfPnz9eGDRuKtTgAAIBrwcNicdp2vXK4Sfzkk08UExMjLy8vff/998rJyZEkZWRkOPzD0QAAACiZHG4SX3zxRc2cOVOzZs1SmTJlbPubN2+u7777rliLAwAAuBY8nLhdrxyuff/+/YX+soq/v7/S09OLoyYAAAC4mMNNYmhoqA4ePGjav2HDBt1yyy3FUhQAAMC1ZLE4b7teOdwkPv744xoyZIg2b94si8WiY8eOacGCBRo+fLgGDhzojBoBAABwjTm8BM6zzz6rgoIC3XPPPTp//rxatmwpq9Wq4cOHa/Dgwc6oEQAAwKmu57eQncXhJtFisejf//63RowYoYMHD+rs2bOKioqSj4+PM+oDAACAC1z1Ytqenp6KiooqzloAAABcgiDRzOEmsXXr1rL8xTe5Zs2af1QQAADAtcZvN5s53CTWr1/f7u+8vDzt2LFDP/74o+Li4oqrLgAAALiQw03ipEmTCt0/duxYnT179h8XBAAAcK3x4opZsS0E/uijj+rdd98trtMBAADAha76xZXLJScnq2zZssV1OgAAgGuGINHM4SaxS5cudn8bhqHjx49r27ZtGj16dLEVBgAAANdxuEn09/e3+9vDw0M1a9bU+PHj1a5du2IrDAAA4Frh7WYzh5rE/Px89enTR3Xr1lX58uWdVRMAAABczKEXV0qVKqV27dopPT3dSeUAAABcexYn/t/1yuG3m+vUqaOff/7ZGbUAAAC4hIfFedv1yuEm8cUXX9Tw4cO1dOlSHT9+XJmZmXYbAAAArn9FfiZx/Pjxevrpp9WhQwdJ0v3332/383yGYchisSg/P7/4qwQAAHCi6znxc5YiN4njxo3TgAED9PXXXzuzHgAAAJQARW4SDcOQJLVq1cppxQAAALiChdW0TRx6JpEvEAAAwD04tE7irbfe+reN4unTp/9RQQAAANcazySaOdQkjhs3zvSLKwAAALjxONQkdu/eXcHBwc6qBQAAwCV4os6syE0izyMCAIAblQd9jkmRX1y59HYzAAAAbnxFThILCgqcWQcAAIDL8OKKmcM/ywcAAIAbn0MvrgAAANyIeCTRjCQRAAAAJiSJAADA7XmIKPFyJIkAAAAwIUkEAABuj2cSzWgSAQCA22MJHDOmmwEAAGBCkggAANweP8tnRpIIAAAAE5JEAADg9ggSzUgSAQAAYEKSCAAA3B7PJJqRJAIAAJRQr7zyiiwWi4YOHWrbl52drfj4eFWoUEE+Pj7q2rWrTpw4Yfe5lJQUxcbGqly5cgoODtaIESN04cIFh65NkwgAANyexeK87Wpt3bpVb7/9turVq2e3f9iwYVqyZIkWLVqkdevW6dixY+rSpYvteH5+vmJjY5Wbm6uNGzdq3rx5mjt3rsaMGePQ9WkSAQCA2/Nw4nY1zp49qx49emjWrFkqX768bX9GRoZmz56tiRMn6u6771ajRo00Z84cbdy4UZs2bZIkrVy5Unv27NF7772n+vXrq3379nrhhRf01ltvKTc316HvBAAAAE6Sk5OjzMxMuy0nJ+cvPxMfH6/Y2Fi1adPGbv/27duVl5dnt79WrVqqXLmykpOTJUnJycmqW7euQkJCbGNiYmKUmZmp3bt3F7lumkQAAOD2LBaL07akpCT5+/vbbUlJSVes5YMPPtB3331X6JjU1FR5enoqICDAbn9ISIhSU1NtY/7cIF46fulYUfF2MwAAgBMlJiYqISHBbp/Vai107C+//KIhQ4Zo1apVKlu27LUo74pIEgEAgNuzOHGzWq3y8/Oz267UJG7fvl1paWlq2LChSpcurdKlS2vdunWaOnWqSpcurZCQEOXm5io9Pd3ucydOnFBoaKgkKTQ01PS286W/L40pCppEAACAEuKee+7Rrl27tGPHDtvWuHFj9ejRw/bPZcqU0erVq22f2b9/v1JSUhQdHS1Jio6O1q5du5SWlmYbs2rVKvn5+SkqKqrItTDdDAAA3F5JWUzb19dXderUsdvn7e2tChUq2Pb37dtXCQkJCgwMlJ+fnwYPHqzo6Gg1a9ZMktSuXTtFRUWpZ8+emjBhglJTUzVq1CjFx8dfMcEsDE0iAADAdWTSpEny8PBQ165dlZOTo5iYGE2fPt12vFSpUlq6dKkGDhyo6OhoeXt7Ky4uTuPHj3foOhbDMIziLt7Vsh1bUBzAdaR8k0GuLgGAk2R9/6bLrr1g+69OO3ePRpWcdm5nIkkEAABur4TMNpcovLgCAAAAE5JEAADg9ixEiSYkiQAAADAhSQQAAG6P1MyM7wQAAAAmJIkAAMDt8UyiGUkiAAAATEgSAQCA2yNHNCNJBAAAgAlJIgAAcHs8k2hGkwgAANweU6tmfCcAAAAwIUkEAABuj+lmM5JEAAAAmJAkAgAAt0eOaEaSCAAAABOSRAAA4PZ4JNGMJBEAAAAmJIkAAMDtefBUoglNIgAAcHtMN5sx3QwAAAATkkQAAOD2LEw3m5AkAgAAwIQkEQAAuD2eSTQjSQQAAIAJSSIAAHB7LIFjRpIIAAAAE5JEAADg9ngm0YwmEQAAuD2aRDOmmwEAAGBCkggAANwei2mbkSQCAADAhCQRAAC4PQ+CRBOSRAAAAJiQJAIAALfHM4lmJIkAAAAwIUkEAABuj3USzWgSAQCA22O62YzpZgAAAJiQJAIAALfHEjhmJIkAAAAwIUkEAABuj2cSzUgSAQAAYEKSiBJp+7atmvvubO3d86NOnjypSVPf0t33tJEk5eXl6c2pk7Xhm/X69ddf5Ovjo6bRd2jIsKcVHBxiO8eRI4c16fUJ2vH9d8rLy1ONW2sqfvAQ3d60matuC3B7Hh4WjRrQQQ93aKKQCn46fjJD85ds1iuzltvGvDPuUfW83/7f05Xf7lGnQdNtf9evVUkvDumsRrUrKz/f0OLVOzTyjU90Liv3mt0LbiwsgWNGkogSKSvrvGrWrKnEUc+bjmVnZ2vf3j3qP2CgPlz0qSZOeVNHDh/WkEED7cYNfnKA8vPzNevdeXp/0aeqWbOWBscP0O8nT16r2wBwmad7t9XjD7bQsFcWqX6XFzVq6udKiGujJx9uZTduxbe7VaVNom2LS5xjOxYW5K9lMwfr0C8n1bLn6+oU/5aiqoVq1vie1/p2gBsaSSJKpDtbtNKdLVoVeszX11dv/2eO3b7Ef49Wj+7/0vFjxxQWHq4//jitlKNHNO6Fl3RrzVqSpCEJT+vDDxbq4MEDqhgU5PR7AGDW7LZbtHTdD1q+YbckKeX4aXW7t7Ea146wG5ebe0EnTp0p9BztW9RR3oV8DU36SIZhSJIGv/Shti16TrfcXFE///K7c28CNySCRDOSRNwQzp49K4vFIl8/P0lSQEB5ValaVUs+X6zz58/rwoUL+vijDxVYoYKiomq7uFrAfW3a+bNa315T1SsHS5Lq3nqTouvfopXf7rEb16JxDR1dnaSdn43WlOceUqC/t+2Y1bO08vLybQ2iJGXlXJxmvqN+tWtwF7gReVgsTtuuVy5PEvfu3atNmzYpOjpatWrV0r59+zRlyhTl5OTo0Ucf1d133/2Xn8/JyVFOTo7dPqOUVVar1ZllowTJycnR5Imvq32HWPn4+EiSLBaL3vnPXA196kndcXtDeXh4KDAwUNPf/o/8/P1dXDHgvl6fs0p+PmW187NRys83VKqURc+/tVQffLnNNmbVxr36fM1OHfntlG6pVFHjBt+nz98cqFZxb6igwNDaLfv1akIXDet1j95cuFbeXp568alOkqTQIP79BoqLS5PE5cuXq379+ho+fLgaNGig5cuXq2XLljp48KCOHj2qdu3aac2aNX95jqSkJPn7+9ttr72adI3uAK6Wl5enEQlDZBiG/j1mnG2/YRh6+cVxCgysoDn/XaAFHyxS67vb6Kn4ATp5Ms2FFQPu7cF2DdW9fRP1fm6eoh95Vf3GzNfQnveox31NbWMWrdiuZet2affBY1qy9gd1eWqmGtepopaNa0iS9v6cqsfHzNdTPe/R6eSJOvLVyzry2yml/p4po6DAVbeG65zFidv1yqVJ4vjx4zVixAi9+OKL+uCDD/TII49o4MCBeumllyRJiYmJeuWVV/4yTUxMTFRCQoLdPqMUKaI7yMvL04inh+r4sWOaNWeeLUWUpC2bN2n9urX6Jnmrbf+/x9TWpuSN+t/ixer7eH9XlQ24tZeHdtbrc1Zp0YrtkqTdB4+pcligRvRpqwVLNhf6mSO/ndLJP86o2s1BWrvlJ0nSh8u36cPl2xQc6KtzWTkyDOmpR+/W4V9PXbN7AW50Lk0Sd+/erd69e0uSunXrpjNnzujBBx+0He/Ro4d++OGHvzyH1WqVn5+f3cZU843vUoOYcvSo3p49VwEB5e2OZ2VlSZLpWRCLh0WGQdIAuIpXWU8VXPbvYH6BIQ+PK//n6KbgAFXw91bq75mmY2mnz+hcVq4ejGmo7Nw8rd60r9hrhpsgSjRx+Ysrlv//H3EPDw+VLVtW/n96XszX11cZGRmuKg0udP7cOe3bu1f79u6VJP3266/at3evjh87pry8PA0f9pT27P5RSa++roL8fP1+8qR+P3lSebkXH16/rX59+fn5adRzz2r/vn06cuSwJr7+qn779Te1aHmXC+8McG9frN+lkX1jdO+dtVU5LFD3t66npx5trf+t2SlJ8vby1MtDO+v2ulVUOSxQd91+qz6a1F+HfvldqzbutZ1nwEMtVb9WJVWvHKwnurXUpJHdNGba/5RxNstVtwYUixkzZqhevXq24Cs6Olpffvml7Xh2drbi4+NVoUIF+fj4qGvXrjpx4oTdOVJSUhQbG6ty5copODhYI0aM0IULFxyuxaXTzVWqVNGBAwdUrdrFt9GSk5NVuXJl2/GUlBSFhYW5qjy40O7dP6pfn162v1+fcPE50/s7PaAB8YO09uuLz6p269rJ7nP/mfNfNbm9qcqXv/iSyrQpk/X4Y3G6cCFP1arX0JQ331LNWrWu3Y0AsJPw6iI9/2RHTXnuIQWV99Hxkxma/fG3evmdi/8RzC8wVKfGTepxX1MF+Hrp+MkMfZW8T+OnL1Vu3v/9R65xnQiNGhArn3Ke2n/khAa99L7eX7bVVbeFG0BJ+Vm+SpUq6ZVXXlGNGjVkGIbmzZunTp066fvvv1ft2rU1bNgwLVu2TIsWLZK/v78GDRqkLl266Ntvv5Uk5efnKzY2VqGhodq4caOOHz+uXr16qUyZMnr55ZcdqsVi/HkNgWts5syZuvnmmxUbG1vo8eeee05paWn6z3/+49B5sx1vlgFcJ8o3GeTqEgA4Sdb3b7rs2psPOW/msmm1f/bWfWBgoF577TU9+OCDCgoK0sKFC22P5+3bt0+RkZFKTk5Ws2bN9OWXX6pjx446duyYQkIu/grZzJkzNXLkSJ08eVKenp5Fvq5Lk8QBAwb85XFHO14AAICr4czlDAtbrs9q/fvl+vLz87Vo0SKdO3dO0dHR2r59u/Ly8tSmTRvbmFq1aqly5cq2JjE5OVl169a1NYiSFBMTo4EDB2r37t1q0KBBket2+TOJAAAArubM91YKW64vKenKy/Xt2rVLPj4+slqtGjBggD777DNFRUUpNTVVnp6eCggIsBsfEhKi1NRUSVJqaqpdg3jp+KVjjnD5YtoAAAA3ssKW6/urFLFmzZrasWOHMjIy9PHHHysuLk7r1q1zdpkmNIkAAABOnG4uytTyn3l6eqp69eqSpEaNGmnr1q2aMmWKHnroIeXm5io9Pd0uTTxx4oRCQ0MlSaGhodqyZYvd+S69/XxpTFEx3QwAAFCCFRQUKCcnR40aNVKZMmW0evVq27H9+/crJSVF0dHRkqTo6Gjt2rVLaWn/9+tiq1atkp+fn6Kiohy6LkkiAABweyVlCZzExES1b99elStX1pkzZ7Rw4UKtXbtWK1askL+/v/r27auEhAQFBgbKz89PgwcPVnR0tJo1ayZJateunaKiotSzZ09NmDBBqampGjVqlOLj4x3+sRGaRAAAgBIiLS1NvXr10vHjx+Xv76969eppxYoVatu2rSRp0qRJ8vDwUNeuXZWTk6OYmBhNnz7d9vlSpUpp6dKlGjhwoKKjo+Xt7a24uDiNHz/e4Vpcuk6is7BOInDjYp1E4MblynUStx8x/+xjcWlUxc9p53YmnkkEAACACdPNAADA7ZWMJxJLFppEAAAAukQTppsBAABgQpIIAADcXklZAqckIUkEAACACUkiAABwexaCRBOSRAAAAJiQJAIAALdHkGhGkggAAAATkkQAAACiRBOaRAAA4PZYAseM6WYAAACYkCQCAAC3xxI4ZiSJAAAAMCFJBAAAbo8g0YwkEQAAACYkiQAAAESJJiSJAAAAMCFJBAAAbo91Es1IEgEAAGBCkggAANwe6ySa0SQCAAC3R49oxnQzAAAATEgSAQAAiBJNSBIBAABgQpIIAADcHkvgmJEkAgAAwIQkEQAAuD2WwDEjSQQAAIAJSSIAAHB7BIlmNIkAAAB0iSZMNwMAAMCEJBEAALg9lsAxI0kEAACACUkiAABweyyBY0aSCAAAABOSRAAA4PYIEs1IEgEAAGBCkggAAECUaEKTCAAA3B5L4Jgx3QwAAAATkkQAAOD2WALHjCQRAAAAJiSJAADA7REkmpEkAgAAwIQkEQAAgCjRhCQRAAAAJiSJAADA7bFOohlNIgAAcHssgWPGdDMAAABMSBIBAIDbI0g0I0kEAAAoIZKSktSkSRP5+voqODhYnTt31v79++3GZGdnKz4+XhUqVJCPj4+6du2qEydO2I1JSUlRbGysypUrp+DgYI0YMUIXLlxwqBaaRAAA4PYsFudtjli3bp3i4+O1adMmrVq1Snl5eWrXrp3OnTtnGzNs2DAtWbJEixYt0rp163Ts2DF16dLFdjw/P1+xsbHKzc3Vxo0bNW/ePM2dO1djxoxx7DsxDMNwrPySL9uxRhnAdaR8k0GuLgGAk2R9/6bLrv3rHzlOO3el8tar/uzJkycVHBysdevWqWXLlsrIyFBQUJAWLlyoBx98UJK0b98+RUZGKjk5Wc2aNdOXX36pjh076tixYwoJCZEkzZw5UyNHjtTJkyfl6elZpGuTJAIAAMjitC0nJ0eZmZl2W05O0ZrSjIwMSVJgYKAkafv27crLy1ObNm1sY2rVqqXKlSsrOTlZkpScnKy6devaGkRJiomJUWZmpnbv3l3kb4QmEQAAwImSkpLk7+9vtyUlJf3t5woKCjR06FA1b95cderUkSSlpqbK09NTAQEBdmNDQkKUmppqG/PnBvHS8UvHioq3mwEAgNtz5jqJiYmJSkhIsNtntf79FHR8fLx+/PFHbdiwwVml/SWaRAAA4PacuQSO1WotUlP4Z4MGDdLSpUu1fv16VapUybY/NDRUubm5Sk9Pt0sTT5w4odDQUNuYLVu22J3v0tvPl8YUBdPNAAAAJYRhGBo0aJA+++wzrVmzRlWrVrU73qhRI5UpU0arV6+27du/f79SUlIUHR0tSYqOjtauXbuUlpZmG7Nq1Sr5+fkpKiqqyLWQJAIAALdXUn6WLz4+XgsXLtTnn38uX19f2zOE/v7+8vLykr+/v/r27auEhAQFBgbKz89PgwcPVnR0tJo1ayZJateunaKiotSzZ09NmDBBqampGjVqlOLj4x1KNFkCB8B1hSVwgBuXK5fAOZ6R67Rzh/kXbckZSbJcoVudM2eOevfuLeniYtpPP/203n//feXk5CgmJkbTp0+3m0o+evSoBg4cqLVr18rb21txcXF65ZVXVLp00fNBmkQA1xWaRODG5comMTUjz2nnDvUv47RzOxPPJAIAAMCEZxIBAABKyDOJJQlJIgAAAExIEgEAgNsjSDSjSQQAAG6vpCyBU5Iw3QwAAAATkkQAAOD2LEw4m5AkAgAAwIQkEQAAgCDRhCQRAAAAJiSJAADA7REkmpEkAgAAwIQkEQAAuD3WSTSjSQQAAG6PJXDMmG4GAACACUkiAABwe0w3m5EkAgAAwIQmEQAAACY0iQAAADDhmUQAAOD2eCbRjCQRAAAAJiSJAADA7bFOohlNIgAAcHtMN5sx3QwAAAATkkQAAOD2CBLNSBIBAABgQpIIAABAlGhCkggAAAATkkQAAOD2WALHjCQRAAAAJiSJAADA7bFOohlJIgAAAExIEgEAgNsjSDSjSQQAAKBLNGG6GQAAACYkiQAAwO2xBI4ZSSIAAABMSBIBAIDbYwkcM5JEAAAAmFgMwzBcXQRwtXJycpSUlKTExERZrVZXlwOgGPHvN+BaNIm4rmVmZsrf318ZGRny8/NzdTkAihH/fgOuxXQzAAAATGgSAQAAYEKTCAAAABOaRFzXrFarnn/+eR5qB25A/PsNuBYvrgAAAMCEJBEAAAAmNIkAAAAwoUkEAACACU0iAAAATGgScV1KSkpSkyZN5Ovrq+DgYHXu3Fn79+93dVkAisGMGTNUr149+fn5yc/PT9HR0fryyy9dXRbgdmgScV1at26d4uPjtWnTJq1atUp5eXlq166dzp075+rSAPxDlSpV0iuvvKLt27dr27Ztuvvuu9WpUyft3r3b1aUBboUlcHBDOHnypIKDg7Vu3Tq1bNnS1eUAKGaBgYF67bXX1LdvX1eXAriN0q4uACgOGRkZki7+hwTAjSM/P1+LFi3SuXPnFB0d7epyALdCkojrXkFBge6//36lp6drw4YNri4HQDHYtWuXoqOjlZ2dLR8fHy1cuFAdOnRwdVmAWyFJxHUvPj5eP/74Iw0icAOpWbOmduzYoYyMDH388ceKi4vTunXrFBUV5erSALdBkojr2qBBg/T5559r/fr1qlq1qqvLAeAkbdq0UbVq1fT222+7uhTAbZAk4rpkGIYGDx6szz77TGvXrqVBBG5wBQUFysnJcXUZgFuhScR1KT4+XgsXLtTnn38uX19fpaamSpL8/f3l5eXl4uoA/BOJiYlq3769KleurDNnzmjhwoVau3atVqxY4erSALfCdDOuSxaLpdD9c+bMUe/eva9tMQCKVd++fbV69WodP35c/v7+qlevnkaOHKm2bdu6ujTArdAkAgAAwIRfXAEAAIAJTSIAAABMaBIBAABgQpMIAAAAE5pEAAAAmNAkAgAAwIQmEQAAACY0iQAAADChSQRw1Xr37q3OnTvb/r7rrrs0dOjQa17H2rVrZbFYlJ6e7rRrXH6vV+Na1AkAxYUmEbjB9O7dWxaLRRaLRZ6enqpevbrGjx+vCxcuOP3an376qV544YUijb3WDVOVKlU0efLka3ItALgRlHZ1AQCK37333qs5c+YoJydHX3zxheLj41WmTBklJiaaxubm5srT07NYrhsYGFgs5wEAuB5JInADslqtCg0NVUREhAYOHKg2bdrof//7n6T/mzZ96aWXFB4erpo1a0qSfvnlF3Xr1k0BAQEKDAxUp06ddOTIEds58/PzlZCQoICAAFWoUEHPPPOMLv/p98unm3NycjRy5EjdfPPNslqtql69umbPnq0jR46odevWkqTy5cvLYrGod+/ekqSCggIlJSWpatWq8vLy0m233aaPP/7Y7jpffPGFbr31Vnl5eal169Z2dV6N/Px89e3b13bNmjVrasqUKYWOHTdunIKCguTn56cBAwYoNzfXdqwotf/Z0aNHdd9996l8+fLy9vZW7dq19cUXX/yjewGA4kKSCLgBLy8vnTp1yvb36tWr5efnp1WrVkmS8vLyFBMTo+joaH3zzTcqXbq0XnzxRd1777364Ycf5OnpqTfeeENz587Vu+++q8jISL3xxhv67LPPdPfdd1/xur169VJycrKmTp2q2267TYcPH9bvv/+um2++WZ988om6du2q/fv3y8/PT15eXpKkpKQkvffee5o5c6Zq1Kih9evX69FHH1VQUJBatWqlX375RV26dFF8fLz69++vbdu26emnn/5H309BQYEqVaqkRYsWqUKFCtq4caP69++vsLAwdevWze57K1u2rNauXasjR46oT58+qlChgl566aUi1X65+Ph45ebmav369fL29taePXvk4+Pzj+4FAIqNAeCGEhcXZ3Tq1MkwDMMoKCgwVq1aZVitVmP48OG24yEhIUZOTo7tM/Pnzzdq1qxpFBQU2Pbl5OQYXl5exooVKwzDMIywsDBjwoQJtuN5eXlGpUqVbNcyDMNo1aqVMWTIEMMwDGP//v2GJGPVqlWF1vn1118bkow//vjDti87O9soV66csXHjRruxffv2NR5++GHDMAwjMTHRiIqKsjs+cuRI07kuFxERYUyaNOmKxy8XHx9vdO3a1fZ3XFycERgYaJw7d862b8aMGYaPj4+Rn59fpNovv+e6desaY8eOLXJNAHAtkSQCN6ClS5fKx8dHeXl5Kigo0COPPKKxY8fajtetW9fuOcSdO3fq4MGD8vX1tTtPdna2Dh06pIyMDB0/flxNmza1HStdurQaN25smnK+ZMeOHSpVqlShCdqVHDx4UOfPn1fbtm3t9ufm5qpBgwaSpL1799rVIUnR0dFFvsaVvPXWW3r33XeVkpKirKws5ebmqn79+nZjbrvtNpUrV87uumfPntUvv/yis2fP/m3tl3vqqac0cOBArVy5Um3atFHXrl1Vr169f3wvAFAcaBKBG1Dr1q01Y8YMeXp6Kjw8XKVL2/+r7u3tbff32bNn1ahRIy1YsMB0rqCgoKuq4dL0sSPOnj0rSVq2bJluuukmu2NWq/Wq6iiKDz74QMOHD9cbb7yh6Oho+fr66rXXXtPmzZuLfI6rqb1fv36KiYnRsmXLtHLlSiUlJemNN97Q4MGDr/5mAKCY0CQCNyBvb29Vr169yOMbNmyoDz/8UMHBwfLz8yt0TFhYmDZv3qyWLVtKki5cuKDt27erYcOGhY6vW7euCgoKtG7dOrVp08Z0/FKSmZ+fb9sXFRUlq9WqlJSUKyaQkZGRtpdwLtm0adPf3+Rf+Pbbb3XHHXfoySeftO07dOiQadzOnTuVlZVla4A3bdokHx8f3XzzzQoMDPzb2gtz8803a8CAARowYIASExM1a9YsmkQAJQJvNwNQjx49VLFiRXXq1EnffPONDh8+rLVr1+qpp57Sr7/+KkkaMmSIXnnlFS1evFj79u3Tk08++ZdrHFapUkVxcXF67LHHtHjxYts5P/roI0lSRESELBaLli5dqpMnT+rs2bPy9fXV8OHDNWzYMM2bN0+HDh3Sd999p2nTpmnevHmSpAEDBujAgQMaMWKE9u/fr4ULF2ru3LlFus/ffvtNO3bssNv++OMP1ahRQ9u2bdOKFSv0008/afTo0dq6davp87m5uerbt6/27NmjL774Qs8//7wGDRokDw+PItV+uaFDh2rFihU6fPiwvvvuO3399deKjIws0r0AgNO5+qFIAMXrzy+uOHL8+PHjRq9evYyKFSsaVqvVuOWWW4zHH3/cyMjIMAzj4osqQ4YMMfz8/IyAgAAjISHB6NWr1xVfXDEMw8jKyjKGDRtmhIWFGZ6enkb16tWNd99913Z8/PjxRmhoqGGxWIy4uDjDMC6+bDN58mSjZs2aRpkyZYygoCAjJibGWLdune1zS5YsMapXr25YrVajRYsWxrvvvlukF1ckmbb58+cb2dnZRu/evQ1/f38jICDAGDhwoPHss88at912m+l7GzNmjFGhQgXDx8fHePzxx43s7GzbmL+r/fIXVwYNGmRUq1bNsFqtRlBQkNGzZ0/j999/v+I9AMC1ZDGMKzx1DgAAALfFdDMAAABMaBIBAABgQpMIAAAAE5pEAAAAmNAkAgAAwIQmEQAAACY0iQAAADChSQQAAIAJTSIAAABMaBIBAABgQpMIAAAAk/8HFn5/S4Lwl6cAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intializing BERT mulltingual model by assigning different weight to the labels**"
      ],
      "metadata": {
        "id": "fynQR9Zp4bi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(labels_train))\n",
        "\n",
        "# Step 3: Fine-tuning\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "# Calculate class weights manually (higher weight for class 2, the minority class)\n",
        "total_samples = len(labels_train)\n",
        "class_2_count = torch.sum(labels_train == 2)\n",
        "class_3_count = torch.sum(labels_train == 3)\n",
        "\n",
        "class_2_weight = total_samples / (2.0 * class_2_count)\n",
        "class_3_weight = total_samples / (2.0 * class_3_count)\n",
        "class_2_weight *= 2\n",
        "\n",
        "# Convert to tensor and move to the same device as the model\n",
        "class_weights = torch.tensor([class_2_weight, class_3_weight]).to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)  # Use class weights in the loss function\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "gradient_accumulation_steps = 2\n",
        "num_train_steps = len(train_dataloader) // gradient_accumulation_steps\n",
        "num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * num_train_steps)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "patience = 2\n",
        "no_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_mask, labels = batch\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Optional gradient clipping\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "        correct_predictions += (predicted_labels == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader) * gradient_accumulation_steps\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            logits = outputs.logits\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "            val_correct_predictions += (predicted_labels == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    val_losses.append(average_val_loss)\n",
        "    val_accuracy = val_correct_predictions / val_total_predictions\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {average_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if average_val_loss < best_val_loss:\n",
        "        best_val_loss = average_val_loss\n",
        "        no_improvement = 0\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "\n",
        "    if no_improvement >= patience:\n",
        "        print(\"No improvement on the validation set. Finish training.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJd2kGItHbVr",
        "outputId": "7f9e27e0-1624-4f94-aa88-2ea70afe08f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 8.4635, Train Accuracy: 0.6594, Validation Loss: 1.5868, Validation Accuracy: 0.6858\n",
            "Epoch 2/10, Train Loss: 1.9213, Train Accuracy: 0.6804, Validation Loss: 0.6332, Validation Accuracy: 0.6858\n",
            "Epoch 3/10, Train Loss: 1.1565, Train Accuracy: 0.7223, Validation Loss: 0.5353, Validation Accuracy: 0.7558\n",
            "Epoch 4/10, Train Loss: 0.9669, Train Accuracy: 0.7804, Validation Loss: 0.5681, Validation Accuracy: 0.7550\n",
            "Epoch 5/10, Train Loss: 0.8396, Train Accuracy: 0.8112, Validation Loss: 0.5376, Validation Accuracy: 0.7558\n",
            "No improvement on the validation set. Finish training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Initialize evaluation metrics\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Evaluate on the test data\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "\n",
        "        predictions.extend(predicted_labels.cpu().numpy())\n",
        "        true_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average=\"macro\")\n",
        "recall = recall_score(true_labels, predictions, average=\"macro\")\n",
        "f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Print the classification report\n",
        "target_names = [\"2\", \"3\"]  # Replace with your actual class names\n",
        "print(classification_report(true_labels, predictions, target_names=target_names))\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02a8d55-e0db-46ff-cdf7-58edbee78321",
        "id": "RGfeJUbyMTOy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6808\n",
            "Precision: 0.6920\n",
            "Recall: 0.6356\n",
            "F1-score: 0.6305\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.71      0.38      0.49       692\n",
            "           3       0.67      0.89      0.77       987\n",
            "\n",
            "    accuracy                           0.68      1679\n",
            "   macro avg       0.69      0.64      0.63      1679\n",
            "weighted avg       0.69      0.68      0.65      1679\n",
            "\n",
            "Confusion Matrix:\n",
            "[[262 430]\n",
            " [106 881]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix when class weight assigned**"
      ],
      "metadata": {
        "id": "4wIEtTFw4vvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "iQcVdTlvSGpS",
        "outputId": "53c06f13-e260-49b9-cbf3-f99212d2cb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[262 430]\n",
            " [106 881]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT model with Smoothed Cross Entropy loss function**"
      ],
      "metadata": {
        "id": "IUoTuUMz47-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmoothedCrossEntropyLoss(torch.nn.Module):\n",
        "    def __init__(self, smoothing=0.1, weight=None):\n",
        "        super(SmoothedCrossEntropyLoss, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        log_prob = torch.nn.functional.log_softmax(inputs, dim=-1)\n",
        "        nll_loss = -log_prob.gather(dim=-1, index=targets.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "\n",
        "        smooth_loss = -log_prob.mean(dim=-1)\n",
        "\n",
        "        if self.weight is not None:\n",
        "            nll_loss = nll_loss * self.weight\n",
        "            smooth_loss = smooth_loss * self.weight\n",
        "\n",
        "        loss = (1.0 - self.smoothing) * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# Change the loss function to SmoothedCrossEntropyLoss\n",
        "loss_fn = SmoothedCrossEntropyLoss(smoothing=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "P84wugVPgJ2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(labels_train))\n",
        "\n",
        "# Step 3: Fine-tuning\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "# Calculate class weights manually (higher weight for class 2, the minority class)\n",
        "total_samples = len(labels_train)\n",
        "class_2_count = torch.sum(labels_train == 2)\n",
        "class_3_count = torch.sum(labels_train == 3)\n",
        "\n",
        "class_2_weight = total_samples / (2.0 * class_2_count)\n",
        "class_3_weight = total_samples / (2.0 * class_3_count)\n",
        "class_2_weight *= 2\n",
        "\n",
        "# Convert to tensor and move to the same device as the model\n",
        "class_weights = torch.tensor([class_2_weight, class_3_weight]).to(device)\n",
        "\n",
        "loss_fn = SmoothedCrossEntropyLoss(smoothing=0.1)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "gradient_accumulation_steps = 2\n",
        "num_train_steps = len(train_dataloader) // gradient_accumulation_steps\n",
        "num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * num_train_steps)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "patience = 2\n",
        "no_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_mask, labels = batch\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Optional gradient clipping\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "        correct_predictions += (predicted_labels == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader) * gradient_accumulation_steps\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            logits = outputs.logits\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "            val_correct_predictions += (predicted_labels == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    val_losses.append(average_val_loss)\n",
        "    val_accuracy = val_correct_predictions / val_total_predictions\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {average_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if average_val_loss < best_val_loss:\n",
        "        best_val_loss = average_val_loss\n",
        "        no_improvement = 0\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "\n",
        "    if no_improvement >= patience:\n",
        "        print(\"No improvement on the validation set. Finish training.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf25b22-cb11-4511-ea5b-8caf49f17201",
        "id": "RiGNSG96gM3I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 8.3329, Train Accuracy: 0.6549, Validation Loss: 1.4648, Validation Accuracy: 0.6806\n",
            "Epoch 2/10, Train Loss: 1.8125, Train Accuracy: 0.6827, Validation Loss: 0.6520, Validation Accuracy: 0.6806\n",
            "Epoch 3/10, Train Loss: 1.1994, Train Accuracy: 0.7041, Validation Loss: 0.5262, Validation Accuracy: 0.7476\n",
            "Epoch 4/10, Train Loss: 0.9821, Train Accuracy: 0.7832, Validation Loss: 0.5127, Validation Accuracy: 0.7476\n",
            "Epoch 5/10, Train Loss: 0.8490, Train Accuracy: 0.8115, Validation Loss: 0.5071, Validation Accuracy: 0.7669\n",
            "Epoch 6/10, Train Loss: 0.7334, Train Accuracy: 0.8438, Validation Loss: 0.5342, Validation Accuracy: 0.7617\n",
            "Epoch 7/10, Train Loss: 0.6465, Train Accuracy: 0.8654, Validation Loss: 0.5502, Validation Accuracy: 0.7543\n",
            "No improvement on the validation set. Finish training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Initialize evaluation metrics\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Evaluate on the test data\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "\n",
        "        predictions.extend(predicted_labels.cpu().numpy())\n",
        "        true_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average=\"macro\")\n",
        "recall = recall_score(true_labels, predictions, average=\"macro\")\n",
        "f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Print the classification report\n",
        "target_names = [\"2\", \"3\"]  # Replace with your actual class names\n",
        "print(classification_report(true_labels, predictions, target_names=target_names))\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f12d80-5d12-4de8-8060-9be8361f9a80",
        "id": "O1ykWONgk6JN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6617\n",
            "Precision: 0.6686\n",
            "Recall: 0.6134\n",
            "F1-score: 0.6036\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.68      0.34      0.45       692\n",
            "           3       0.66      0.89      0.76       987\n",
            "\n",
            "    accuracy                           0.66      1679\n",
            "   macro avg       0.67      0.61      0.60      1679\n",
            "weighted avg       0.67      0.66      0.63      1679\n",
            "\n",
            "Confusion Matrix:\n",
            "[[234 458]\n",
            " [110 877]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT model with Focal Loss function**"
      ],
      "metadata": {
        "id": "GEyIJjsL5FTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        log_prob = torch.nn.functional.log_softmax(inputs, dim=-1)\n",
        "        prob = torch.exp(log_prob)\n",
        "        focal_weight = (self.alpha * targets + (1 - self.alpha) * (1 - targets)) * (1 - prob) ** self.gamma\n",
        "        cross_entropy = -log_prob.gather(dim=-1, index=targets.unsqueeze(1))\n",
        "        loss = focal_weight * cross_entropy\n",
        "        return loss.mean()\n",
        "\n",
        "# Change the loss function to FocalLoss\n",
        "loss_fn = FocalLoss(alpha=0.25, gamma=2.0)\n"
      ],
      "metadata": {
        "id": "kZ_iB5MJjLab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(labels_train))\n",
        "\n",
        "# Step 3: Fine-tuning\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "# Calculate class weights manually (higher weight for class 2, the minority class)\n",
        "total_samples = len(labels_train)\n",
        "class_2_count = torch.sum(labels_train == 2)\n",
        "class_3_count = torch.sum(labels_train == 3)\n",
        "\n",
        "class_2_weight = total_samples / (2.0 * class_2_count)\n",
        "class_3_weight = total_samples / (2.0 * class_3_count)\n",
        "class_2_weight *= 2\n",
        "\n",
        "# Convert to tensor and move to the same device as the model\n",
        "class_weights = torch.tensor([class_2_weight, class_3_weight]).to(device)\n",
        "\n",
        "loss_fn = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "gradient_accumulation_steps = 2\n",
        "num_train_steps = len(train_dataloader) // gradient_accumulation_steps\n",
        "num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * num_train_steps)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "patience = 2\n",
        "no_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_mask, labels = batch\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Optional gradient clipping\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "        correct_predictions += (predicted_labels == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader) * gradient_accumulation_steps\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            logits = outputs.logits\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "            val_correct_predictions += (predicted_labels == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    val_losses.append(average_val_loss)\n",
        "    val_accuracy = val_correct_predictions / val_total_predictions\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {average_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if average_val_loss < best_val_loss:\n",
        "        best_val_loss = average_val_loss\n",
        "        no_improvement = 0\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "\n",
        "    if no_improvement >= patience:\n",
        "        print(\"No improvement on the validation set. Finish training.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2001bb1-50e7-4595-f913-aaa3c6743b04",
        "id": "6tJr3PXXjOVY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 8.8577, Train Accuracy: 0.6577, Validation Loss: 1.7462, Validation Accuracy: 0.6806\n",
            "Epoch 2/10, Train Loss: 2.0453, Train Accuracy: 0.6875, Validation Loss: 0.6129, Validation Accuracy: 0.7215\n",
            "Epoch 3/10, Train Loss: 1.1657, Train Accuracy: 0.7393, Validation Loss: 0.5511, Validation Accuracy: 0.7446\n",
            "Epoch 4/10, Train Loss: 0.9688, Train Accuracy: 0.7862, Validation Loss: 0.5462, Validation Accuracy: 0.7461\n",
            "Epoch 5/10, Train Loss: 0.8240, Train Accuracy: 0.8266, Validation Loss: 0.5666, Validation Accuracy: 0.7558\n",
            "Epoch 6/10, Train Loss: 0.7201, Train Accuracy: 0.8557, Validation Loss: 0.5524, Validation Accuracy: 0.7610\n",
            "No improvement on the validation set. Finish training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Initialize evaluation metrics\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Evaluate on the test data\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "\n",
        "        predictions.extend(predicted_labels.cpu().numpy())\n",
        "        true_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision = precision_score(true_labels, predictions, average=\"macro\")\n",
        "recall = recall_score(true_labels, predictions, average=\"macro\")\n",
        "f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Print the classification report\n",
        "target_names = [\"2\", \"3\"]  # Replace with your actual class names\n",
        "print(classification_report(true_labels, predictions, target_names=target_names))\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab7af02-325e-488d-f875-8de9757661ae",
        "id": "829-3FEIqeo9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6593\n",
            "Precision: 0.6627\n",
            "Recall: 0.6122\n",
            "F1-score: 0.6033\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.67      0.34      0.45       692\n",
            "           3       0.66      0.88      0.75       987\n",
            "\n",
            "    accuracy                           0.66      1679\n",
            "   macro avg       0.66      0.61      0.60      1679\n",
            "weighted avg       0.66      0.66      0.63      1679\n",
            "\n",
            "Confusion Matrix:\n",
            "[[238 454]\n",
            " [118 869]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT model with Binary Loss function**"
      ],
      "metadata": {
        "id": "ZKSi9Alm5MDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryCrossEntropyLoss(torch.nn.Module):\n",
        "    def __init__(self, weight=None):\n",
        "        super(BinaryCrossEntropyLoss, self).__init__()\n",
        "        self.weight = weight\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        loss_fn = torch.nn.BCEWithLogitsLoss(weight=self.weight)\n",
        "        return loss_fn(inputs.view(-1), targets.view(-1).float())\n",
        "\n",
        "# Use BinaryCrossEntropyLoss as the loss function\n",
        "loss_fn = BinaryCrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "GRcchCjjjNpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the pre-trained BERT model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=len(labels_train))\n",
        "\n",
        "# Step 3: Fine-tuning\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "# Calculate class weights manually (higher weight for class 2, the minority class)\n",
        "total_samples = len(labels_train)\n",
        "class_2_count = torch.sum(labels_train == 2)\n",
        "class_3_count = torch.sum(labels_train == 3)\n",
        "\n",
        "class_2_weight = total_samples / (2.0 * class_2_count)\n",
        "class_3_weight = total_samples / (2.0 * class_3_count)\n",
        "class_2_weight *= 2\n",
        "\n",
        "# Convert to tensor and move to the same device as the model\n",
        "class_weights = torch.tensor([class_2_weight, class_3_weight]).to(device)\n",
        "\n",
        "loss_fn = BinaryCrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "gradient_accumulation_steps = 2\n",
        "num_train_steps = len(train_dataloader) // gradient_accumulation_steps\n",
        "num_warmup_steps = int(0.1 * num_train_steps)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs * num_train_steps)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "patience = 2\n",
        "no_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_mask, labels = batch\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Optional gradient clipping\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        logits = outputs.logits\n",
        "        predicted_labels = torch.argmax(logits, dim=1)\n",
        "        correct_predictions += (predicted_labels == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader) * gradient_accumulation_steps\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            logits = outputs.logits\n",
        "            predicted_labels = torch.argmax(logits, dim=1)\n",
        "            val_correct_predictions += (predicted_labels == labels).sum().item()\n",
        "            val_total_predictions += labels.size(0)\n",
        "\n",
        "    average_val_loss = val_loss / len(val_dataloader)\n",
        "    val_losses.append(average_val_loss)\n",
        "    val_accuracy = val_correct_predictions / val_total_predictions\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {average_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
        "          f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early Stopping\n",
        "    if average_val_loss < best_val_loss:\n",
        "        best_val_loss = average_val_loss\n",
        "        no_improvement = 0\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "\n",
        "    if no_improvement >= patience:\n",
        "        print(\"No improvement on the validation set. Finish training.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2001bb1-50e7-4595-f913-aaa3c6743b04",
        "id": "Bwz0C0WBoaFo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 8.8577, Train Accuracy: 0.6577, Validation Loss: 1.7462, Validation Accuracy: 0.6806\n",
            "Epoch 2/10, Train Loss: 2.0453, Train Accuracy: 0.6875, Validation Loss: 0.6129, Validation Accuracy: 0.7215\n",
            "Epoch 3/10, Train Loss: 1.1657, Train Accuracy: 0.7393, Validation Loss: 0.5511, Validation Accuracy: 0.7446\n"
          ]
        }
      ]
    }
  ]
}